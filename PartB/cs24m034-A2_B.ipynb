{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11454239,"sourceType":"datasetVersion","datasetId":7176873}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport random\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data_utils\nfrom torchvision import models, datasets, transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pathlib\nimport wandb\nimport gc\n\n# Set matrix multiplication precision for better performance\nif hasattr(torch, 'set_float32_matmul_precision'):\n    torch.set_float32_matmul_precision('medium')\n\nwandb.login(key=\"7f46816d45e3df192c3053bab59032e9d710fef4\")\n\ndef data_generation(dataset_path, num_classes=10, data_augmentation=False, batch_size=32):\n    \n    # Mean and standard deviation values calculated from function get_mean_and_std on training dataset\n    mean = [0.4708, 0.4596, 0.3891]\n    std = [0.1951, 0.1892, 0.1859]\n\n    # Define transformations for training and testing data\n    augment_transform = transforms.Compose([\n        transforms.Resize((224, 224)), \n        transforms.RandomHorizontalFlip(), \n        transforms.RandomRotation(30), \n        transforms.ToTensor(),\n        transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n    ])\n\n    train_transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n        ])\n    \n    test_transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(torch.Tensor(mean), torch.Tensor(std))\n    ])\n\n    # Load datasets\n    train_dataset = datasets.ImageFolder(root = dataset_path + \"train\", transform=train_transform)\n    test_dataset = datasets.ImageFolder(root = dataset_path + \"val\", transform=test_transform)\n    \n    # Split train dataset into train and validation sets\n    train_data_class = dict()\n    for c in range(num_classes):\n        train_data_class[c] = [i for i, label in enumerate(train_dataset.targets) if label == c]\n\n    val_data_indices = []\n    val_ratio = 0.2  # 20% for validation\n    for class_indices in train_data_class.values():\n        num_val = int(len(class_indices) * val_ratio)\n        val_data_indices.extend(random.sample(class_indices, num_val))\n\n    # Create training and validation datasets\n    train_data = torch.utils.data.Subset(train_dataset, [i for i in range(len(train_dataset)) if i not in val_data_indices])\n    val_data = torch.utils.data.Subset(train_dataset, val_data_indices)\n\n    # Number of workers for data loading (adjust based on CPU cores)\n    num_workers = 4\n    \n    # Create optimized data loaders with pinned memory for faster GPU transfer\n    train_loader = DataLoader(\n        train_data, \n        batch_size=batch_size, \n        shuffle=True, \n        num_workers=num_workers,\n        pin_memory=True,\n        persistent_workers=True if num_workers > 0 else False\n    )\n    \n    val_loader = DataLoader(\n        val_data, \n        batch_size=batch_size, \n        shuffle=False, \n        num_workers=num_workers,\n        pin_memory=True,\n        persistent_workers=True if num_workers > 0 else False\n    )\n    \n    test_loader = DataLoader(\n        test_dataset, \n        batch_size=batch_size, \n        shuffle=False, \n        num_workers=num_workers,\n        pin_memory=True,\n        persistent_workers=True if num_workers > 0 else False\n    )\n\n    if data_augmentation:\n        augmented_dataset = datasets.ImageFolder(root = dataset_path + \"train\", transform=augment_transform)\n        augmented_loader = DataLoader(\n            augmented_dataset, \n            batch_size=batch_size, \n            shuffle=True,\n            num_workers=num_workers,\n            pin_memory=True,\n            persistent_workers=True if num_workers > 0 else False\n        )\n        train_loader = torch.utils.data.ConcatDataset([train_loader.dataset, augmented_loader.dataset])\n        train_loader = DataLoader(\n            train_loader, \n            batch_size=batch_size, \n            shuffle=True,\n            num_workers=num_workers,\n            pin_memory=True,\n            persistent_workers=True if num_workers > 0 else False\n        )\n\n    # Get class names\n    classpath = pathlib.Path(dataset_path + \"train\")\n    class_names = sorted([j.name.split('/')[-1] for j in classpath.iterdir() if j.name != \".DS_Store\"])\n\n    return train_loader, val_loader, test_loader, class_names\n\ndef trainCNN(device, train_loader, val_loader, test_loader, model, num_epochs=10, optimizer=\"Adam\"):    \n    criterion = nn.CrossEntropyLoss()\n    if optimizer == \"Adam\":\n        opt_func = optim.Adam(model.parameters(), lr=0.001)\n    \n    # Initialize gradient scaler for mixed precision training\n    scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n\n    for epoch in tqdm(range(num_epochs)):\n        model.train()  # Set the model to training mode\n        running_loss = 0.0\n        total_correct = 0\n        total_samples = 0\n        \n        for inputs, labels in tqdm(train_loader):\n            # Move inputs and labels to device with non-blocking transfer\n            inputs = inputs.to(device, non_blocking=True)\n            labels = labels.to(device, non_blocking=True)\n            \n            opt_func.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n            \n            # Mixed precision forward pass\n            with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n                outputs = model(inputs)  # Forward pass\n                loss = criterion(outputs, labels)  # Compute the loss\n            \n            # Scale gradients and optimize with mixed precision\n            scaler.scale(loss).backward()  # Backward pass\n            scaler.step(opt_func)  # Update parameters\n            scaler.update()  # Update scaler\n\n            # Calculate metrics\n            with torch.no_grad():\n                _, predicted = torch.max(outputs, 1)\n                total_correct += (predicted == labels).sum().item()\n                total_samples += labels.size(0)\n                running_loss += loss.item() * inputs.size(0)\n        \n        # Calculate epoch metrics\n        loss = running_loss / len(train_loader.dataset)\n        accuracy = total_correct / total_samples\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Accuracy: {accuracy * 100:.2f}%, Loss: {loss:.4f}\")\n        wandb.log({'accuracy': accuracy, 'loss': loss})\n\n        # Validation\n        model.eval()\n        with torch.no_grad():\n            val_total_correct = 0\n            val_total_samples = 0\n            val_running_loss = 0.0\n            \n            for val_inputs, val_labels in tqdm(val_loader):\n                val_inputs = val_inputs.to(device, non_blocking=True)\n                val_labels = val_labels.to(device, non_blocking=True)\n                \n                # Mixed precision validation\n                with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n                    val_outputs = model(val_inputs)\n                    val_loss = criterion(val_outputs, val_labels)\n\n                _, val_predicted = torch.max(val_outputs, 1)\n                val_total_correct += (val_predicted == val_labels).sum().item()\n                val_total_samples += val_labels.size(0)\n                val_running_loss += val_loss.item() * val_inputs.size(0)\n\n            val_loss = val_running_loss / len(val_loader.dataset)\n            val_accuracy = val_total_correct / val_total_samples\n            print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Accuracy: {val_accuracy * 100:.2f}%, Validation Loss: {val_loss:.4f}\")\n            wandb.log({'val_accuracy': val_accuracy, 'val_loss': val_loss})\n\n        # Clear cache to avoid memory pressure\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n            gc.collect()\n\n        # Test accuracy evaluation at final epoch\n        if epoch == num_epochs-1:\n            model.eval()\n            with torch.no_grad():\n                test_total_correct = 0\n                test_total_samples = 0\n                test_running_loss = 0.0\n                \n                for test_inputs, test_labels in tqdm(test_loader):\n                    test_inputs = test_inputs.to(device, non_blocking=True)\n                    test_labels = test_labels.to(device, non_blocking=True)\n                    \n                    # Mixed precision testing\n                    with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n                        test_outputs = model(test_inputs)\n                        test_loss = criterion(test_outputs, test_labels)\n    \n                    _, test_predicted = torch.max(test_outputs, 1)\n                    test_total_correct += (test_predicted == test_labels).sum().item()\n                    test_total_samples += test_labels.size(0)\n                    test_running_loss += test_loss.item() * test_inputs.size(0)\n    \n                test_loss = test_running_loss / len(test_loader.dataset)\n                test_accuracy = test_total_correct / test_total_samples\n                print(f\"Test Accuracy: {test_accuracy * 100:.2f}%, Test Loss: {test_loss:.4f}\")\n\ndef feature_extraction(model, device):\n    for params in model.parameters():\n        params.requires_grad = False\n\ndef freeze_till_k(model, device, k):\n    # Counter to track the number of frozen layers\n    frozen_layers = 0\n    \n    for param in model.parameters():\n        # Freeze layers up to the k-th layer\n        if frozen_layers < k:\n            param.requires_grad = False\n            frozen_layers += 1\n        else:\n            # Stop freezing layers after k-th layer\n            break\n\ndef no_freezing(model, device):\n    for params in model.parameters():\n        params.requires_grad = True\n\ndef main():\n    dataset_path = '/kaggle/input/nature/inaturalist_12K/'  \n\n    # You can increase batch size for better GPU utilization if memory allows\n    data_augmentation = True\n    batch_size = 64  # Increased from 32 for better GPU utilization\n    num_classes = 10\n    fine_tuning_method = 2\n    k = 12\n\n    def train():\n        with wandb.init(project=\"Testing_3\") as run:\n            config = wandb.config\n            run_name = \"aug_\" + str(data_augmentation) + \"_bs_\" + str(batch_size) + \"_fine_tune_\" + str(fine_tuning_method) + \"_num_freeze_layer_all\"\n            if fine_tuning_method != 1:\n                run_name = \"aug_\" + str(data_augmentation) + \"_bs_\" + str(batch_size) + \"_fine_tune_\" + str(fine_tuning_method) + \"_num_freeze_layer_\" + str(k)\n            elif fine_tuning_method == 3:\n                run_name = \"aug_\" + str(data_augmentation) + \"_bs_\" + str(batch_size) + \"_fine_tune_\" + str(fine_tuning_method) + \"_num_freeze_layer_none\"\n\n            wandb.run.name = run_name\n            \n            train_loader, val_loader, test_loader, class_names = data_generation(\n                dataset_path, \n                num_classes=10, \n                data_augmentation=data_augmentation, \n                batch_size=batch_size\n            )\n            \n            print(\"Train: \", len(train_loader))\n            print(\"Val: \", len(val_loader))\n            print(\"Test: \", len(test_loader))\n    \n            # Properly detect and use CUDA device for Kaggle\n            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n            print(\"Device: \", device)\n        \n            # Use weights parameter instead of pretrained for newer PyTorch versions\n            if hasattr(models.googlenet, 'pretrained'):\n                model = models.googlenet(pretrained=True)\n            else:\n                model = models.googlenet(weights='IMAGENET1K_V1')\n                \n            model.to(device)\n            \n            # Enable model compilation for PyTorch 2.0+ if available\n            if hasattr(torch, 'compile') and torch.cuda.is_available():\n                #model = torch.compile(model)\n                print(\"Using compiled model for faster training\")\n\n            if fine_tuning_method == 1:\n                feature_extraction(model, device)\n                model.fc = nn.Linear(model.fc.in_features, num_classes)\n                model.to(device)\n                trainCNN(device, train_loader, val_loader, test_loader, model, num_epochs=5, optimizer=\"Adam\")\n            \n            elif fine_tuning_method == 2:\n                freeze_till_k(model, device, k)\n                model.fc = nn.Linear(model.fc.in_features, num_classes)\n                model.to(device)\n                trainCNN(device, train_loader, val_loader, test_loader, model, num_epochs=5, optimizer=\"Adam\")\n\n            else:\n                feature_extraction(model, device)\n                model.fc = nn.Linear(model.fc.in_features, num_classes)\n                model.to(device)\n                trainCNN(device, train_loader, val_loader, test_loader, model, num_epochs=5, optimizer=\"Adam\")\n                \n            # Clean up GPU memory when done\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n                \n    train()\n    wandb.finish()\n    \nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T12:12:04.532104Z","iopub.execute_input":"2025-04-19T12:12:04.532435Z","iopub.status.idle":"2025-04-19T12:21:04.328100Z","shell.execute_reply.started":"2025-04-19T12:12:04.532409Z","shell.execute_reply":"2025-04-19T12:21:04.327213Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250419_121204-xav0c0ej</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/cs24m034-indian-institute-of-technology-madras/Testing_3/runs/xav0c0ej' target=\"_blank\">rural-disco-3</a></strong> to <a href='https://wandb.ai/cs24m034-indian-institute-of-technology-madras/Testing_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/cs24m034-indian-institute-of-technology-madras/Testing_3' target=\"_blank\">https://wandb.ai/cs24m034-indian-institute-of-technology-madras/Testing_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/cs24m034-indian-institute-of-technology-madras/Testing_3/runs/xav0c0ej' target=\"_blank\">https://wandb.ai/cs24m034-indian-institute-of-technology-madras/Testing_3/runs/xav0c0ej</a>"},"metadata":{}},{"name":"stdout","text":"Train:  282\nVal:  32\nTest:  32\nDevice:  cuda\nUsing compiled model for faster training\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/1821765692.py:130: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b799f7b96db34ab9aa12064ce89ba389"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/282 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe2dc867646440d291e0c8dd3681c3b5"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_31/1821765692.py:146: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/5], Accuracy: 62.01%, Loss: 1.1301\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7fa4d6cd2064760aef3a0b78c6555c6"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_31/1821765692.py:180: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/5], Validation Accuracy: 67.38%, Validation Loss: 0.9563\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/282 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f768bcb63e94501b62e132367c6d739"}},"metadata":{}},{"name":"stdout","text":"Epoch [2/5], Accuracy: 72.77%, Loss: 0.8054\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76c92c8e1d504cc699385c9a072f4007"}},"metadata":{}},{"name":"stdout","text":"Epoch [2/5], Validation Accuracy: 67.78%, Validation Loss: 1.0101\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/282 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"701290116bbf4b2588bd4ba14ef840c3"}},"metadata":{}},{"name":"stdout","text":"Epoch [3/5], Accuracy: 78.61%, Loss: 0.6289\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5c210e44f5f4db08e9fb31c66c6831a"}},"metadata":{}},{"name":"stdout","text":"Epoch [3/5], Validation Accuracy: 76.44%, Validation Loss: 0.7011\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/282 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25852eed37554d03b80b247bcc26544f"}},"metadata":{}},{"name":"stdout","text":"Epoch [4/5], Accuracy: 82.59%, Loss: 0.5192\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6699eeaea66d49889667f87f644529ef"}},"metadata":{}},{"name":"stdout","text":"Epoch [4/5], Validation Accuracy: 76.64%, Validation Loss: 0.7035\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/282 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"161e7ce9201d4658bc5db2f53a430e01"}},"metadata":{}},{"name":"stdout","text":"Epoch [5/5], Accuracy: 85.68%, Loss: 0.4314\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ecc6c14d07441a49940931c4d359750"}},"metadata":{}},{"name":"stdout","text":"Epoch [5/5], Validation Accuracy: 80.64%, Validation Loss: 0.5795\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/32 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4c5cea553f14e759f54eee00571ba57"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_31/1821765692.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 68.45%, Test Loss: 1.1325\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▆▇█</td></tr><tr><td>loss</td><td>█▅▃▂▁</td></tr><tr><td>val_accuracy</td><td>▁▁▆▆█</td></tr><tr><td>val_loss</td><td>▇█▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.85683</td></tr><tr><td>loss</td><td>0.43143</td></tr><tr><td>val_accuracy</td><td>0.8064</td></tr><tr><td>val_loss</td><td>0.57945</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">aug_True_bs_64_fine_tune_2_num_freeze_layer_12</strong> at: <a href='https://wandb.ai/cs24m034-indian-institute-of-technology-madras/Testing_3/runs/xav0c0ej' target=\"_blank\">https://wandb.ai/cs24m034-indian-institute-of-technology-madras/Testing_3/runs/xav0c0ej</a><br> View project at: <a href='https://wandb.ai/cs24m034-indian-institute-of-technology-madras/Testing_3' target=\"_blank\">https://wandb.ai/cs24m034-indian-institute-of-technology-madras/Testing_3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250419_121204-xav0c0ej/logs</code>"},"metadata":{}}],"execution_count":5}]}