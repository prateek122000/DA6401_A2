{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11464666,"sourceType":"datasetVersion","datasetId":7184259}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Required Libraries","metadata":{}},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data_utils\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport pathlib\nimport wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:56:01.203131Z","iopub.status.idle":"2025-04-21T18:56:01.203447Z","shell.execute_reply.started":"2025-04-21T18:56:01.203288Z","shell.execute_reply":"2025-04-21T18:56:01.203303Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  cuDNN Benchmarking for Faster Convolutions","metadata":{}},{"cell_type":"code","source":"# Enable cuDNN benchmarking for faster convolution operations\ntorch.backends.cudnn.benchmark = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:56:01.204924Z","iopub.status.idle":"2025-04-21T18:56:01.205231Z","shell.execute_reply.started":"2025-04-21T18:56:01.205075Z","shell.execute_reply":"2025-04-21T18:56:01.205092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"wandb.login(key=\"7f46816d45e3df192c3053bab59032e9d710fef4\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:56:01.206450Z","iopub.status.idle":"2025-04-21T18:56:01.206784Z","shell.execute_reply.started":"2025-04-21T18:56:01.206602Z","shell.execute_reply":"2025-04-21T18:56:01.206616Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **show_images Function**\nThis function is used to display a batch of images in a grid layout with their corresponding class names as titles.\n\n","metadata":{}},{"cell_type":"code","source":"def show_images(class_names, images, labels):\n    num_images = len(images)\n    cols = 6\n    rows = (num_images + cols - 1) // cols  # Auto-calculate required rows\n\n    fig, axes = plt.subplots(rows, cols, figsize=(12, 2 * rows))\n    axes = axes.flatten()\n\n    for i in range(len(axes)):\n        ax = axes[i]\n        if i < num_images:\n            img = np.transpose(images[i], (1, 2, 0))  # CHW â†’ HWC\n            ax.imshow(img)\n            ax.set_title(class_names[labels[i]])\n        ax.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:56:01.208035Z","iopub.status.idle":"2025-04-21T18:56:01.208525Z","shell.execute_reply.started":"2025-04-21T18:56:01.208362Z","shell.execute_reply":"2025-04-21T18:56:01.208377Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ðŸ§  show_images_and_labels Function\nDisplay 3 images per class (10 classes total) in a 10Ã—3 grid. Each image includes the predicted and true class labels in the title. Also logs the images to Weights & Biases (wandb) for experiment tracking.","metadata":{}},{"cell_type":"code","source":"\ndef show_images_and_labels(device, model, test_loader, class_names):\n    model.eval()\n    images_to_log = {}\n    \n    # Track number of images shown per class\n    images_per_class = {class_name: 0 for class_name in class_names}\n\n    # Prepare a 10x3 subplot grid (10 classes, 3 images each)\n    fig, axes = plt.subplots(10, 3, figsize=(15, 30))\n    axes = axes.reshape(10, 3)\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device, non_blocking=True)\n            labels = labels.to(device, non_blocking=True)\n            \n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n\n            for img, label, pred in zip(images, labels, predicted):\n                class_idx = label.item()\n                class_name = class_names[class_idx]\n                \n                if images_per_class[class_name] < 3:\n                    col_idx = images_per_class[class_name]\n                    ax = axes[class_idx][col_idx]\n\n                    img_np = img.permute(1, 2, 0).cpu().numpy()\n                    ax.imshow(img_np)\n                    ax.set_title(f\"Predicted: {class_names[pred.item()]}\\nOriginal: {class_name}\")\n                    ax.axis('off')\n\n                    # Log to wandb\n                    wandb_image = wandb.Image(img_np, caption=f\"Predicted: {class_names[pred.item()]}, Original: {class_name}\")\n                    wandb.log({f\"Image: {class_name}\": wandb_image})\n                    images_to_log[f\"Predicted: {class_names[pred.item()]}, Original: {class_name}\"] = wandb_image\n                    \n                    # Optional print log\n                    print({\n                        f\"Image_{class_name}\": wandb.Image(img_np),\n                        f\"Predicted_{class_name}\": class_names[pred.item()],\n                        f\"Original_{class_name}\": class_name\n                    })\n\n                    images_per_class[class_name] += 1\n\n            if all(count == 3 for count in images_per_class.values()):\n                break\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:56:01.209388Z","iopub.status.idle":"2025-04-21T18:56:01.209715Z","shell.execute_reply.started":"2025-04-21T18:56:01.209549Z","shell.execute_reply":"2025-04-21T18:56:01.209563Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ndef data_generation(dataset_path, num_classes=10, data_augmentation=False, batch_size=32):\n    from torchvision import transforms, datasets\n    import torch\n    from torch.utils.data import DataLoader, Subset, ConcatDataset\n    import random\n    import pathlib\n\n    # Mean and std values from get_mean_and_std\n    mean = [0.4708, 0.4596, 0.3891]\n    std = [0.1951, 0.1892, 0.1859]\n\n    # Define transformations\n    base_transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n\n    augment_transform = transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(30),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std)\n    ])\n\n    # Load datasets\n    train_dataset = datasets.ImageFolder(root=f\"{dataset_path}train\", transform=base_transform)\n    test_dataset = datasets.ImageFolder(root=f\"{dataset_path}val\", transform=base_transform)\n\n    # Stratified validation split\n    train_data_class = {c: [] for c in range(num_classes)}\n    for idx, label in enumerate(train_dataset.targets):\n        train_data_class[label].append(idx)\n\n    val_indices = []\n    for indices in train_data_class.values():\n        val_count = int(len(indices) * 0.2)\n        val_indices.extend(random.sample(indices, val_count))\n\n    train_indices = [i for i in range(len(train_dataset)) if i not in val_indices]\n\n    train_data = Subset(train_dataset, train_indices)\n    val_data = Subset(train_dataset, val_indices)\n\n    # Prepare dataloaders\n    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n\n    # Augment data if required\n    if data_augmentation:\n        augmented_dataset = datasets.ImageFolder(root=f\"{dataset_path}train\", transform=augment_transform)\n        augmented_data = Subset(augmented_dataset, train_indices)\n        combined_data = ConcatDataset([train_data, augmented_data])\n        train_loader = DataLoader(combined_data, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n\n    # Extract class names\n    class_dir = pathlib.Path(f\"{dataset_path}train\")\n    class_names = sorted([folder.name for folder in class_dir.iterdir() if folder.is_dir() and folder.name != \".DS_Store\"])\n\n    return train_loader, val_loader, test_loader, class_names\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:56:01.211094Z","iopub.status.idle":"2025-04-21T18:56:01.211386Z","shell.execute_reply.started":"2025-04-21T18:56:01.211237Z","shell.execute_reply":"2025-04-21T18:56:01.211251Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  data_generation Function\nThis function sets up the data pipeline for training, validation, and testing using PyTorchâ€™s ImageFolder. It supports stratified splitting of the training data and optional data augmentation.\n\n","metadata":{}},{"cell_type":"markdown","source":"#  Custom CNN Model & Training Pipeline\nThis section defines a flexible Convolutional Neural Network (CNN) and a training pipeline that supports dynamic architecture configuration, learning rate scheduling, automatic mixed precision (AMP), and Weights & Biases logging.","metadata":{}},{"cell_type":"code","source":"class ClassCNN(nn.Module):\n    def __init__(self, num_filters, activation_function, filter_multiplier, \n                 filter_sizes, dropout, batch_norm, dense_size, num_classes, \n                 image_size=256):\n        super().__init__()\n        \n        # Network configuration\n        self.activation = getattr(nn, activation_function)()\n        self.layers = nn.ModuleList()\n        current_channels = 3  # Input channels for RGB images\n        output_size = image_size\n        \n        # Build convolutional blocks dynamically\n        for i, kernel_size in enumerate(filter_sizes):\n            out_channels = max(1, int(num_filters * (filter_multiplier ** i)))\n            \n            conv_layer = nn.Conv2d(\n                in_channels=current_channels,\n                out_channels=out_channels,\n                kernel_size=kernel_size,\n                padding=kernel_size//2  # Add padding to maintain spatial dimensions\n            )\n            self.layers.append(conv_layer)\n            \n            if batch_norm:\n                self.layers.append(nn.BatchNorm2d(out_channels))\n                \n            self.layers.append(self.activation)\n            self.layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n            \n            current_channels = out_channels\n            output_size = output_size // 2  # Account for pooling\n        \n        # Calculate flattened dimensions\n        fc_input_size = current_channels * output_size * output_size\n        \n        # Fully connected layers\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(fc_input_size, dense_size),\n            self.activation,\n            nn.Dropout(dropout),\n            nn.Linear(dense_size, num_classes)\n        )\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return self.classifier(x)\n\n\ndef train_cnn_model(device, train_loader, val_loader, test_loader, \n                   model, num_epochs=10, optimizer_type=\"Adam\"):\n    \"\"\"Optimized training procedure for CNN models\"\"\"\n    \n    # Setup loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)\n    scaler = torch.cuda.amp.GradScaler()\n\n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        epoch_loss = 0.0\n        correct = 0\n        total = 0\n        \n        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n            images, labels = images.to(device), labels.to(device)\n            \n            with torch.cuda.amp.autocast():\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n            \n            optimizer.zero_grad(set_to_none=True)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n\n            _, predicted = outputs.max(1)\n            correct += predicted.eq(labels).sum().item()\n            total += labels.size(0)\n            epoch_loss += loss.item() * images.size(0)\n\n        # Calculate metrics\n        train_loss = epoch_loss / len(train_loader.dataset)\n        train_acc = correct / total\n        print(f\"Train | Accuracy: {train_acc*100:.2f}% | Loss: {train_loss:.4f}\")\n        wandb.log({'train_acc': train_acc, 'train_loss': train_loss})\n\n        # Validation phase\n        model.eval()\n        val_loss, val_acc = evaluate_model(\n            model, val_loader, criterion, device, \"Validation\"\n        )\n        wandb.log({'val_acc': val_acc, 'val_loss': val_loss})\n        scheduler.step(val_acc)  # Adjust learning rate\n\n        # Final test evaluation\n        if epoch == num_epochs - 1:\n            test_loss, test_acc = evaluate_model(\n                model, test_loader, criterion, device, \"Test\"\n            )\n            wandb.log({'test_acc': test_acc, 'test_loss': test_loss})\n\n\ndef evaluate_model(model, data_loader, criterion, device, phase_name):\n    \"\"\"Shared evaluation procedure for validation and testing\"\"\"\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels in tqdm(data_loader, desc=phase_name):\n            images, labels = images.to(device), labels.to(device)\n            \n            with torch.cuda.amp.autocast():\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n            \n            _, predicted = outputs.max(1)\n            correct += predicted.eq(labels).sum().item()\n            total += labels.size(0)\n            running_loss += loss.item() * images.size(0)\n    \n    avg_loss = running_loss / len(data_loader.dataset)\n    accuracy = correct / total\n    print(f\"{phase_name} | Accuracy: {accuracy*100:.2f}% | Loss: {avg_loss:.4f}\")\n    return avg_loss, accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:56:01.212409Z","iopub.status.idle":"2025-04-21T18:56:01.212720Z","shell.execute_reply.started":"2025-04-21T18:56:01.212558Z","shell.execute_reply":"2025-04-21T18:56:01.212571Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hyperparameter Sweep Configuration","metadata":{}},{"cell_type":"code","source":"def get_sweep_config():\n    return {\n        'method': 'bayes',\n        'project': 'Testing_2',\n        'metric': {\n            'name': 'accuracy',\n            'goal': 'maximize'\n        },\n        'parameters': {\n            'data_augmentation': {\n                'values': [True, False]\n            },\n            'batch_size': {\n                'values': [32, 64]\n            },\n            'batch_norm': {\n                'values': [True]\n            },\n            'dropout': {\n                'values': [0.2, 0.3, 0.4]\n            },\n            'dense_size': {\n                'values': [256, 512]\n            },\n            'num_filters': {\n                'values': [16, 32, 64]\n            },\n            'filter_size': {\n                'values': [3, 5]\n            },\n            'activation_function': {\n                'values': ['ReLU', 'LeakyReLU', 'GELU']\n            },\n            'filter_multiplier': {\n                'values': [2, 4]\n            }\n        }\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:56:01.213657Z","iopub.status.idle":"2025-04-21T18:56:01.213976Z","shell.execute_reply.started":"2025-04-21T18:56:01.213816Z","shell.execute_reply":"2025-04-21T18:56:01.213830Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" # Training Function: train_model()\nThis function wraps the full model training process with dynamic hyperparameter support via Weights & Biases (wandb) sweeps. It initializes data, the model, and performs training using the best configuration from the sweep.\n\n","metadata":{}},{"cell_type":"code","source":"def train_model():\n    with wandb.init(project=\"Testing_2\") as run:\n        config = wandb.config\n\n        run_name = (\n            f\"aug_{config.data_augmentation}_bs_{config.batch_size}_norm_{config.batch_norm}_\"\n            f\"dropout_{config.dropout}_fc_{config.dense_size}_nfilters_{config.num_filters}_\"\n            f\"ac_{config.activation_function}_fmul_{config.filter_multiplier}\"\n        )\n        wandb.run.name = run_name\n\n        dataset_path = '/kaggle/input/nature/inaturalist_12K/'\n        num_classes = 10\n        image_size = 256\n        filter_sizes = [config.filter_size] * 5\n\n        train_loader, val_loader, test_loader, class_names = data_generation(\n            dataset_path,\n            num_classes=num_classes,\n            data_augmentation=config.data_augmentation,\n            batch_size=config.batch_size\n        )\n\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        print(\"Device in use:\", device)\n\n        model = ClassCNN(\n            num_filters=config.num_filters,\n            activation_function=config.activation_function,\n            filter_multiplier=config.filter_multiplier,\n            filter_sizes=filter_sizes,\n            dropout=config.dropout,\n            batch_norm=config.batch_norm,\n            dense_size=config.dense_size,\n            num_classes=num_classes,\n            image_size=image_size\n        ).to(device)\n\n        trainCNN(device, train_loader, val_loader, test_loader, model, num_epochs=10, optimizer=\"Adam\")\n        \n        # Show the images and the labels (pred and true)\n        #show_images_and_labels(device, model, test_loader, class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:56:01.215037Z","iopub.status.idle":"2025-04-21T18:56:01.215337Z","shell.execute_reply.started":"2025-04-21T18:56:01.215189Z","shell.execute_reply":"2025-04-21T18:56:01.215202Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Main Function: main()\nThis function orchestrates the hyperparameter sweep process using W&B. It defines the sweep configuration, initializes the sweep, and starts the sweep agent to perform multiple training runs with different hyperparameter combinations.","metadata":{}},{"cell_type":"code","source":"def main():\n    sweep_config = get_sweep_config()\n    sweep_id = wandb.sweep(sweep=sweep_config)\n    wandb.agent(sweep_id, project=\"Testing_2\", function=train_model, count=50)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T18:56:01.216109Z","iopub.status.idle":"2025-04-21T18:56:01.216365Z","shell.execute_reply.started":"2025-04-21T18:56:01.216240Z","shell.execute_reply":"2025-04-21T18:56:01.216251Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null}]}